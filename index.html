<!DOCTYPE html>
<html class="no-js" lang="en">
 <!-- change made in online -->
<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Bishwamittra Ghosh</title>
	<link rel="shortcut icon" href="images/pp.jpg" type="image/x-icon">
	<link rel="icon" href="images/pp.jpg" type="image/x-icon">
    <link href="https://fonts.googleapis.com/css?family=Lato:300,400,700,900" rel="stylesheet">
    
    <link href="css/bootstrap.min.css" rel="stylesheet">
    <link href="css/styles.css" rel="stylesheet">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css">
    <!-- <link rel="stylesheet" href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css"> -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  	<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"></script>
  	<link rel="stylesheet" href="libs/font-awesome/css/font-awesome.min.css">
  	<link href="css/styles.css" rel="stylesheet">
    
</head>

<body>
    

    <div id="mobile-menu-open" class="shadow-large">
        <i class="fa fa-bars" aria-hidden="true"></i>
    </div>
    <!-- End #mobile-menu-toggle -->
    <header>
        <div id="mobile-menu-close">
            <span>Close</span> <i class="fa fa-times" aria-hidden="true"></i>
        </div>
        <ul id="menu" class="shadow">
            <li>
                <a href="index.html" onClick="window.location='index.html'"">Home</a>
            </li>
            <li>
                    <a href="publications.html" onClick="window.location='publications.html'"">Publications</a>
            </li>
            <li>
                <a href="education.html" onClick="window.location='education.html'"">Education</a>
            </li>
            <li>
                <a href="blog.html" onClick="window.location='blog.html'"">Blog</a>
            </li>
            <li>
                <a href="activities.html" onClick="window.location='activities.html'"">Activities</a>
            </li>
            <li>
                    <a href="news.html" onClick="window.location='news.html'"">News</a>
            </li>
            
            
            
            
        </ul>
    </header>
    
    <div id="about">
        <div class="container">
            <div class="row">
                <div class="col-md-2">
                	 <img class="img-responsive" src="images/pp.jpg" max-width: 100% \ 9 alt="Chania" > 
                	 
                    
                </div>
                <div class="col-md-8">
                	<h2> Bishwamittra Ghosh</h2>
                	<p> Postdoctoral Researcher </p>
                	<p> Max Planck Institute for Software Systems, Germany</p>
                    <p> <i class="fa fa-envelope-o"></i>  bghosh[at]mpi-sws.org </p>
                    <p> 
                        <a href="resume/bghosh_CV.pdf">[CV]</a> 
                        <a href="research_statement/bghosh_research_statement.pdf">[Research statement]</a>
                        <a href="teaching_statement/bghosh_teaching_statement.pdf">[Teaching statement]</a> 
                    </p>
                    <p> <a href="https://scholar.google.com/citations?user=xO4PpdAAAAAJ&hl=en&oi=ao" class="icon-block"><i class="ai ai-google-scholar-square ai-2x"></i></a>   
                         <a href="https://github.com/bishwamittra" class="icon-block"><i class="fa fa-github" style="font-size:36px"></i></a>
                         <a href="https://dblp.uni-trier.de/pers/hd/g/Ghosh:Bishwamittra" class="icon-block"><i class="ai ai-dblp-square ai-2x"></i></a>  
                         <a href="https://www.semanticscholar.org/author/Bishwamittra-Ghosh/49522533?utm_source=alert_email&utm_content=EditAuthorProfile&utm_campaign=AlertEmails_Ad_WeeklyAlerts&utm_term=AuthorCitation&utm_medium=268435" <i class="ai ai-semantic-scholar-square ai-2x"></i></a>  
                         <a href="https://www.researchgate.net/profile/Bishwamittra_Ghosh" class="icon-block"><i class="ai ai-researchgate-square ai-2x"></i></a>
                    </p>
                </div>

            </div>
            <br>
				<p align="justify">
                I am a postdoctoral researcher at <a href="https://www.mpi-sws.org">Max Planck Institute for Software Systems, Germany</a>. My research interest is on trustworthy machine learning, generative models, and formal methods. Currently, I work with <a href="https://scholar.google.com/citations?user=Bz3APTsAAAAJ&hl=en&oi=ao"> Krishna P. Gummadi </a> on understanding the foundation of Large Language Models (LLMs) in terms of memorization and learning through the lens of formal methods.
                </p>
				<br>
				<p align="justify">
                
				I have completed my Ph.D. from the <a  href="https://www.comp.nus.edu.sg/">
				School of Computing</a>, <a href="https://nus.edu.sg/"> National University of Singapore (NUS) </a> on 30 September 2023 under the supervision of <a href="https://www.comp.nus.edu.sg/~meel/">Prof. Kuldeep S. Meel</a>.
                My Ph.D. thesis is <a href="publication/thesis/bghosh_thesis.pdf"><em>Interpretability and Fairness in Machine Learning: A Formal Methods Approach</em></a>.
				</p>
				<br>
				<p align="justify">
                I have completed my bachelor's degree (BSc.) in Computer Science and Engineering from <a href="http://buet.ac.bd/"> 
                Bangladesh University of Engineering and Technology (BUET) </a> in September 2017.   
                My undergraduate thesis is on socio-spatial group queries advised by <a href="https://sites.google.com/site/mohammedeunusali/">Dr. Mohammed Eunus 
                Ali</a>.
				</p>
                <br>

                
                <figure align="center">
                    <img src="research_statement/research_keyword.png" alt="My Research Interests" style="width:85%">
                </figure>
                <br>
                
                <p align="justify">
                The figure above illustrates a keyword graph representing my research interests. Thematic areas are enclosed in ellipses, while methodological tools rooted in formal methods are shown in boxes. Red arrows indicate directions for future research, emphasizing the integration of these themes and exploration beyond their current scope. For a detailed discussion, please refer to my <a href="research_statement/bghosh_research_statement.pdf">research statement</a>.                     
                <br>
                <!-- <p align="justify" style="color:red"><strong>I am on the job market.</strong><br></p> -->
                <!-- <p align="justify">Application materials: <a href="resume/bghosh.pdf">[Resume]</a> <a href="research_statement/bghosh_research_statement.pdf">[Research Statement]</a> -->
                <!-- <p align="justify"><a href="resume/bghosh.pdf">[Resume]</a> </p>     -->
                </p>
				

        </div>
    </div>
    <!-- End #about -->
    <div id="publication">

            
            

        <h2 class="heading"><a href="publications.html">Publications</a></h2>
        
        <div class="publication-block">

            <h1 class="heading">2025</h1>
    
            <div class="container">

                <div class="row">
                    <div class="col-md-1">
                            <span class="serial">
                            <strong> ICLR  </strong><br />
                        </span>
    
                    </div>
                    <div class="col-md-8">
                        <h3><a href="https://arxiv.org/pdf/2412.16100">Logical Consistency of Large Language Models in Fact-checking</a></h3>
                        <h4> <u> Bishwamittra Ghosh</u>, Sarah Hasan, Naheed Anjum Arafat, Arijit Khan</h4> 
                            <!-- <h4>Proceedings of AAAI, 2025.</h4> -->
                        <button type="button" class="btn btn-primary collapsed" data-toggle="collapse" data-target="#llm_consistency">Abstract</button>
                        <a href="https://arxiv.org/pdf/2412.16100" class="btn btn-primary" role="button">PDF</a>
                        <a href="publication/iclr_2025/llm_logical_consistency.pdf" class="btn btn-primary" role="button"	>Slides</a>
                        <a href="https://www.youtube.com/watch?v=W0wr_WsSGrw" class="btn btn-primary" role="button"	>Talk</a>
                        <!-- <a href="publication/splitFusionNet_2024/paper.bib" class="btn btn-primary" role="button"	>Cite</a>
                        <a href="https://www.dropbox.com/s/7njeqwajgtb6696/lexr.mov?dl=0" class="btn btn-primary" role="button"	>Talk</a>
                        <a href="https://www.dropbox.com/s/01qg1x3xt7as7n0/lexr.pptx?dl=0" class="btn btn-primary" role="button"	>Slides</a>
                        <a href="https://drive.google.com/file/d/1sbKyQJwH7lb8KXx-RBQeTYTfEVNuvYfV/view?usp=sharing" class="btn btn-primary" role="button"	><small>Podcast [Experimental]</small></a> -->
                                                        
    
                        <div id="llm_consistency" class="collapse">
                            <p align="justify">
                                In recent years, large language models (LLMs) have demonstrated significant success in performing varied natural language tasks such as language translation, question-answering, summarizing, fact-checking, etc. Despite LLMs' impressive ability to generate human-like texts, LLMs are infamous for their inconsistent responses -- a meaning-preserving change in the input query results in an inconsistent response and attributes to vulnerabilities of LLMs such as hallucination, jailbreaking, etc. Consequently, existing research focuses on simple paraphrasing-based consistency assessment of LLMs, and ignores complex queries that necessitates an even better understanding of logical reasoning by an LLM. Our work therefore addresses the logical inconsistency of LLMs under complex logical queries with primitive logical operators, e.g., negation, conjunction, and disjunction. As a test bed, we consider retrieval-augmented LLMs on a fact-checking task involving propositional logic queries from real-world knowledge graphs (KGs). Our contributions are three-fold. Benchmark: We introduce three logical fact-checking datasets over KGs for community development towards logically consistent LLMs. Assessment: We propose consistency measures of LLMs on propositional logic queries as input and demonstrate that existing LLMs lack logical consistency, specially on complex queries. Improvement: We employ supervised fine-tuning to improve the logical consistency of LLMs on the complex fact-checking task with KG contexts.
    
                            </p>
                        </div>
                    </div>
    
                </div>
                
                
                <div class="row">
                    <br>
                    <div class="col-md-1">
                            <span class="serial">
                            <strong> AAAI  </strong><br />
                        </span>
    
                    </div>
                    <div class="col-md-8">
                        <h3><a href="https://arxiv.org/pdf/2410.08111">Active Fourier Auditor for Estimating Distributional Properties of ML Models</a></h3>
                        <h4>Ayoub Ajarra, <u> Bishwamittra Ghosh</u>, Debabrota Basu</h4> 
                            <!-- <h4>Proceedings of AAAI, 2025.</h4> -->
                        <button type="button" class="btn btn-primary collapsed" data-toggle="collapse" data-target="#afa">Abstract</button>
                        <a href="https://arxiv.org/pdf/2410.08111" class="btn btn-primary" role="button">PDF</a>
                        <!-- <a href="publication/splitFusionNet_2024/paper.bib" class="btn btn-primary" role="button"	>Cite</a>
                        <a href="publication/fssgq-ghosh-slides.pdf" class="btn btn-primary" role="button"	>Slides</a>
                        <a href="https://github.com/ReAILe/bias-explainer" class="btn btn-primary" role="button"	>Code</a>
                        <a href="https://www.dropbox.com/s/7njeqwajgtb6696/lexr.mov?dl=0" class="btn btn-primary" role="button"	>Talk</a>
                        <a href="https://www.dropbox.com/s/01qg1x3xt7as7n0/lexr.pptx?dl=0" class="btn btn-primary" role="button"	>Slides</a>
                        <a href="https://drive.google.com/file/d/1sbKyQJwH7lb8KXx-RBQeTYTfEVNuvYfV/view?usp=sharing" class="btn btn-primary" role="button"	><small>Podcast [Experimental]</small></a> -->
                                                        
    
                        <div id="afa" class="collapse">
                            <p align="justify">
                                With the pervasive deployment of Machine Learning (ML) models
                                in real-world applications, verifying and auditing properties of ML models
                                have become a central concern. In this work, we focus on three properties: robustness, individual fairness, and group fairness. We discuss two approaches
                                for auditing ML model properties: estimation with and without reconstruction of the target model under audit. Though the first approach is studied
                                in the literature, the second approach remains unexplored. For this purpose,
                                we develop a new framework that quantifies different properties in terms of
                                the Fourier coefficients of the ML model under audit but does not parametrically reconstruct it. We propose the Active Fourier Auditor (AFA), which
                                queries sample points according to the Fourier coefficients of the ML model,
                                and further estimates the properties. We derive high probability error bounds
                                on AFA’s estimates, along with the worst-case lower bounds on the sample
                                complexity to audit them. Numerically we demonstrate on multiple datasets
                                and models that AFA is more accurate and sample-efficient to estimate the
                                properties of interest than the baselines.
    
                            </p>
                        </div>
                    </div>
    
                </div>
    
                <div class="row">
                    <br>
                    <div class="col-md-1">
                            <span class="serial">
                            <strong> WSDM  </strong><br />
                        </span>
    
                    </div>
                    <div class="col-md-8">
                        <h3><a href="https://arxiv.org/pdf/2404.12957">Towards Reliable Latent Knowledge Estimation in LLMs: Zero-Prompt Many-Shot Based Factual Knowledge Extraction</a></h3>
                        <h4>Qinyuan Wu, Mohammad Aflah Khan, Soumi Das, Vedant Nanda, <u> Bishwamittra Ghosh</u>, Camila Kolling, Till Speicher, Laurent Bindschaedler, Krishna P. Gummadi, Evimaria Terzi</h4> 
                            <!-- <h4>Proceedings of WSDM, 2025.</h4> -->
                        <button type="button" class="btn btn-primary collapsed" data-toggle="collapse" data-target="#zplke">Abstract</button>
                            <a href="https://arxiv.org/pdf/2404.12957" class="btn btn-primary" role="button">PDF</a>
                            <!-- <a href="publication/splitFusionNet_2024/paper.bib" class="btn btn-primary" role="button"	>Cite</a>
                            <a href="publication/fssgq-ghosh-slides.pdf" class="btn btn-primary" role="button"	>Slides</a>
                            <a href="https://github.com/ReAILe/bias-explainer" class="btn btn-primary" role="button"	>Code</a>
                            <a href="https://www.dropbox.com/s/7njeqwajgtb6696/lexr.mov?dl=0" class="btn btn-primary" role="button"	>Talk</a>
                            <a href="https://www.dropbox.com/s/01qg1x3xt7as7n0/lexr.pptx?dl=0" class="btn btn-primary" role="button"	>Slides</a>
                            <a href="https://drive.google.com/file/d/1sbKyQJwH7lb8KXx-RBQeTYTfEVNuvYfV/view?usp=sharing" class="btn btn-primary" role="button"	><small>Podcast [Experimental]</small></a> -->
                                                            
    
                        <div id="zplke" class="collapse">
                            <p align="justify">
                                In this paper, we focus on the challenging task of reliably estimating
                                factual knowledge that is embedded inside large language models
                                (LLMs). To avoid reliability concerns with prior approaches, we
                                propose to eliminate prompt engineering when probing LLMs for
                                factual knowledge. Our approach, called Zero-Prompt Latent Knowledge Estimator (ZP-LKE), leverages the in-context learning ability of
                                LLMs to communicate both the factual knowledge question as well
                                as the expected answer format. Our knowledge estimator is both
                                conceptually simpler (i.e., doesn’t depend on meta-linguistic judgments of LLMs) and easier to apply (i.e., is not LLM-specific), and
                                we demonstrate that it can surface more of the latent knowledge embedded in LLMs. We also investigate how different design choices
                                affect the performance of ZP-LKE. Using the proposed estimator,
                                we perform a large-scale evaluation of the factual knowledge of a
                                variety of open-source LLMs, like OPT, Pythia, Llama(2), Mistral,
                                Gemma, etc. over a large set of relations and facts from the Wikidata
                                knowledge base. We observe differences in the factual knowledge
                                between different model families and models of different sizes, that
                                some relations are consistently better known than others but that
                                models differ in the precise facts they know, and differences in the
                                knowledge of base models and their finetuned counterparts.
    
                            </p>
                        </div>
                    </div>
    
                </div>

                
                <div class="row">
                    <br>
                    <div class="col-md-1">
                            <span class="serial">
                            <strong> ECAI  </strong><br />
                        </span>
    
                    </div>
                    <div class="col-md-8">
                        <h3><a href="https://arxiv.org/pdf/2403.07151">History-Aware and Dynamic Client Contribution in Federated Learning</a></h3>
                        <h4> <u> Bishwamittra Ghosh</u>, Debabrota Basu, Fu Huazhu, Wang Yuan, Renuga Kanagavelu, Jiang Jin Peng, Liu Yong, Goh Siow Mong Rick, Wei Qingsong</h4> 
                            <!-- <h4>Proceedings of AAAI, 2025.</h4> -->
                        <button type="button" class="btn btn-primary collapsed" data-toggle="collapse" data-target="#fl_contrib">Abstract</button>
                        <a href="https://arxiv.org/pdf/2403.07151" class="btn btn-primary" role="button">PDF</a>
                        <!-- <a href="publication/iclr_2025/llm_logical_consistency.pdf" class="btn btn-primary" role="button"	>Slides</a> -->
                        <!-- <a href="https://www.youtube.com/watch?v=W0wr_WsSGrw" class="btn btn-primary" role="button"	>Talk</a> -->
                        <!-- <a href="publication/splitFusionNet_2024/paper.bib" class="btn btn-primary" role="button"	>Cite</a>
                        <a href="https://www.dropbox.com/s/7njeqwajgtb6696/lexr.mov?dl=0" class="btn btn-primary" role="button"	>Talk</a>
                        <a href="https://www.dropbox.com/s/01qg1x3xt7as7n0/lexr.pptx?dl=0" class="btn btn-primary" role="button"	>Slides</a>
                        <a href="https://drive.google.com/file/d/1sbKyQJwH7lb8KXx-RBQeTYTfEVNuvYfV/view?usp=sharing" class="btn btn-primary" role="button"	><small>Podcast [Experimental]</small></a> -->
                                                        
    
                        <div id="fl_contrib" class="collapse">
                            <p align="justify">
                                Federated Learning (FL) is a collaborative machine learning (ML) approach, where multiple clients participate in training an ML model without exposing their private data. Fair and accurate assessment of client contributions is an important problem in FL to facilitate incentive allocation and encourage diverse clients to participate in a unified model training. Existing methods for assessing client contribution adopts co-operative game-theoretic concepts, such as Shapley values, but under simplified assumptions. In this paper, we propose a history-aware game-theoretic framework, called FLContrib, to assess client contributions when a subset of clients (potentially non-i.i.d.) participate in each epoch of FL training. By exploiting the FL training process and linearity of Shapley value, we develop FLContrib that yields a historical timeline of client contributions as training progresses over epochs. Additionally, to assess client contribution under limited computational budget, we propose a scheduling procedure that considers a two-sided fairness criteria to perform expensive Shapley value computation only in a subset of training epochs. Empirically, FLContrib is the most efficient and consistently accurate method in contribution assessment across multiple utility functions. To demonstrate the benefits of history-aware client contributions, we apply FLContrib to detect dishonest clients conducting data poisoning in FL.
    
                            </p>
                        </div>
                    </div>
    
                </div>
    
            </div>
        
        </div>

        <div class="publication-block">

            <h1 class="heading">2024</h1>
    
            <div class="container">
                <div class="row">
                    <div class="col-md-1">
                            <span class="serial">
                            <strong> CAI  </strong><br />
                        </span>
    
                    </div>
                    <div class="col-md-8">
                        <h3><a href="publication/splitFusionNet_2024/main.pdf">Split Learning of Multi-Modal Medical Image Classification</a></h3>
                        <h4> <u>Bishwamittra Ghosh</u>, Yuan Wang, Huazhu Fu, Wei Qingsong, Yong Liu, Rick Goh</h4> 
                            <!-- <h4>Proceedings of IEEE CAI, 2024.</h4> -->
                        <button type="button" class="btn btn-primary collapsed" data-toggle="collapse" data-target="#splitfusionnet">Abstract</button>
                            <a href="publication/splitFusionNet_2024/main.pdf" class="btn btn-primary" role="button">PDF</a>
                            <a href="publication/splitFusionNet_2024/paper.bib" class="btn btn-primary" role="button"	>Cite</a>
                            <!-- <a href="publication/fssgq-ghosh-slides.pdf" class="btn btn-primary" role="button"	>Slides</a> -->
                            <!-- <a href="https://github.com/ReAILe/bias-explainer" class="btn btn-primary" role="button"	>Code</a> -->
                            <!-- <a href="https://www.dropbox.com/s/7njeqwajgtb6696/lexr.mov?dl=0" class="btn btn-primary" role="button"	>Talk</a> -->
                            <!-- <a href="https://www.dropbox.com/s/01qg1x3xt7as7n0/lexr.pptx?dl=0" class="btn btn-primary" role="button"	>Slides</a> -->
                            <a href="https://drive.google.com/file/d/1sbKyQJwH7lb8KXx-RBQeTYTfEVNuvYfV/view?usp=sharing" class="btn btn-primary" role="button"	><small>Podcast [Experimental]</small></a>
                                                            
        
                        <div id="splitfusionnet" class="collapse">
                            <p align="justify">
                                In the past decades, machine learning (ML) has made significant progress in medical image classification. 
                                The success can be attributed to two factors: (i) unique patient data collected and processed 
                                by clinics/hospitals and (ii) corresponding ML models solving the underlying classification task. 
                                In practice, patient data may contain sensitive information unique to patients’ demography; and 
                                ML models often require higher computational resources beyond the affordability of an individual hospital.
                                <br>
                                Considering practical concerns, we explore a collaborative ML approach in which 
                                the data provider, referred to as the client, aims to leverage the computational 
                                resources of a server in jointly training a unified ML model without the need 
                                to share any raw data. Specifically, we focus on the skin lesion classification 
                                problem using a real-world dataset containing multi-modal image inputs and 
                                multi-label ground truth.
                                <br>
                                To enable collaborative yet privacy-preserving skin lesion classification, 
                                we develop a learning framework called SplitFusionNet based on u-shape split 
                                learning. The key idea of SplitFusionNet is to split the ML model into a 
                                (client, server) partition of deep neural network layers: the client 
                                layers process multi-modal input data and multi-labels, while server 
                                layers perform computationally extensive mid-layer computations. 
                                Additionally, we apply lossless compression and decompression to 
                                improve the communication cost between the client and the server. 
                                Experimentally, SplitFusionNet requires less training pipeline 
                                time than non-split centralized training while achieving equal 
                                predictive performance.

                            </p>
                        </div>
                    </div>
    
                </div>
    
            </div>
        
        </div>

        
        <div class="publication-block">

            <h1 class="heading">2023</h1>
    
            <div class="container">
                <div class="row">
                    <div class="col-md-1">
                            <span class="serial">
                            <strong> FAccT  </strong><br />
                        </span>
    
                    </div>
                    <div class="col-md-8">
                        <h3><a href="https://arxiv.org/pdf/2206.00667.pdf">“How Biased are Your Features?”: Computing Fairness Influence Functions with Global Sensitivity Analysis</a></h3>
                        <h4> <u>Bishwamittra Ghosh</u>, Debabrota Basu, Kuldeep S. Meel</h4> 
                            <!-- <h4>Proceedings of FAccT, 2023.</h4> -->
                        <button type="button" class="btn btn-primary collapsed" data-toggle="collapse" data-target="#fairXplainer">Abstract</button>
                            <a href="https://arxiv.org/pdf/2206.00667.pdf" class="btn btn-primary" role="button">PDF</a>
                            <a href="publication/fairXplainer/paper.bib" class="btn btn-primary" role="button"	>Cite</a>
                            <!-- <a href="publication/fssgq-ghosh-slides.pdf" class="btn btn-primary" role="button"	>Slides</a> -->
                            <a href="https://github.com/ReAILe/bias-explainer" class="btn btn-primary" role="button"	>Code</a>
                            <!-- <a href="https://www.dropbox.com/s/7njeqwajgtb6696/lexr.mov?dl=0" class="btn btn-primary" role="button"	>Talk</a> -->
                            <!-- <a href="https://www.dropbox.com/s/01qg1x3xt7as7n0/lexr.pptx?dl=0" class="btn btn-primary" role="button"	>Slides</a> -->
                            <a href="https://drive.google.com/file/d/1CB_LL_Rt-A3aJDS_uA-JUS-wuaWlRDvf/view?usp=sharing" class="btn btn-primary" role="button"><small>Podcast [Experimental]</small></a>
                                                            
        
                        <div id="fairXplainer" class="collapse">
                            <p align="justify">
                                Fairness in machine learning has attained significant focus due to the widespread application 
                                in high-stake decision-making tasks. Unregulated machine learning classifiers can exhibit 
                                bias towards certain demographic groups in data, thus the quantification and mitigation of 
                                classifier bias is a central concern in fairness in machine learning. In this paper, 
                                we aim to quantify the influence of different features in a dataset on the bias of a 
                                classifier. To do this, we introduce the Fairness Influence Function (FIF). 
                                This function breaks down bias into its components among individual features and the 
                                intersection of multiple features. The key idea is to represent existing group 
                                fairness metrics as the difference of the scaled conditional variances in the classifier’s 
                                prediction and apply a decomposition of variance according to global sensitivity analysis. 
                                To estimate FIFs, we instantiate an algorithm FairXplainer that applies variance decomposition 
                                of classifier’s prediction following local regression. Experiments demonstrate that 
                                FairXplainer captures FIFs of individual feature and intersectional features, provides 
                                a better approximation of bias based on FIFs, demonstrates higher correlation of FIFs 
                                with fairness interventions, and detects changes in bias due to fairness affirmative/punitive 
                                actions in the classifier.
                            </p>
                        </div>
                    </div>
    
                </div>
    
                <br>
                <div class="row">
                    <div class="col-md-1">
                        <span class="serial">
                        <strong> VLDB  </strong><br />
                    </span>
    
                    </div>
                    <div class="col-md-8">
                        <h3><a href="https://arxiv.org/pdf/2301.06426.pdf">Neighborhood-based Hypergraph Core Decomposition</a></h3>
                        <h4> Naheed Anjum Arafat, Arijit Khan, Arpit Kumar Rai, <u>Bishwamittra Ghosh</u></h4> 
                            <!-- <h4>Proceedings of VLDB, 2023.</h4> -->
                        <button type="button" class="btn btn-primary collapsed" data-toggle="collapse" data-target="#hypergraph">Abstract</button>
                            <a href="https://arxiv.org/pdf/2301.06426.pdf" class="btn btn-primary" role="button">PDF</a>
                            <!-- <a href="publication/fairXplainer/paper.bib" class="btn btn-primary" role="button"	>Cite</a> -->
                            <!-- <a href="publication/fssgq-ghosh-slides.pdf" class="btn btn-primary" role="button"	>Slides</a> -->
                            <!-- <a href="https://github.com/ReAILe/bias-explainer" class="btn btn-primary" role="button"	>Code</a> -->
                            <!-- <a href="https://www.dropbox.com/s/7njeqwajgtb6696/lexr.mov?dl=0" class="btn btn-primary" role="button"	>Talk</a> -->
                            <!-- <a href="https://www.dropbox.com/s/01qg1x3xt7as7n0/lexr.pptx?dl=0" class="btn btn-primary" role="button"	>Slides</a> -->
                                                            
    
                        <div id="hypergraph" class="collapse">
                            <p align="justify">
                                We propose neighborhood-based core decomposition: a novel way of decomposing hypergraphs
                                into hierarchical neighborhood-cohesive subhypergraphs. Alternative approaches
                                to decomposing hypergraphs, e.g., reduction to clique or bipartite graphs,
                                are not meaningful in certain applications, the later also results in inefficient
                                decomposition; while existing degree-based hypergraph decomposition does not 
                                distinguish nodes with different neighborhood sizes. Our case studies show that 
                                the proposed decomposition is more effective than degree and clique graph-based decompositions 
                                in disease intervention and in extracting provably approximate and application-wise meaningful 
                                densest subhypergraphs. We propose three algorithms: Peel, its efficient variant E-Peel, 
                                and a novel local algorithm: Local- core with parallel implementation. Our most efficient parallel 
                                algorithm Local-core(P) decomposes hypergraph with 27M nodes and 17M hyperedges in-memory 
                                within 91 seconds by adopting various optimizations. Finally, we develop a new hypergraph-core model, 
                                the (neighborhood, degree)-core by considering both neighborhood and degree constraints, 
                                design its decomposition algorithm Local-core+Peel, and demonstrate its superiority 
                                in spreading diffusion.
                            </p>
                        </div>
                    </div>
                        
                </div>
            </div>
        
        </div>

        
        <div class="publication-block">
            <h1 class="heading">2022</h1>

            <div class="container">
                <div class="row">
                    <div class="col-md-1">
                            <span class="serial">
                            <strong> AAAI  </strong><br />
                        </span>

                    </div>
                    <div class="col-md-8">
                        <h3><a href="https://arxiv.org/pdf/2109.09447.pdf">Algorithmic Fairness Verification with Graphical Models</a></h3>
                        <h4> <u>Bishwamittra Ghosh</u>, Debabrota Basu, Kuldeep S. Meel</h4> 
                        <!-- <h4>Proceedings of AAAI, 2022.</h4>     -->
                        <button type="button" class="btn btn-primary collapsed" data-toggle="collapse" data-target="#fvgm">Abstract</button>
                            <a href="https://arxiv.org/pdf/2109.09447.pdf" class="btn btn-primary" role="button">PDF</a>
                            <a href="publication/fvgm/paper.bib" class="btn btn-primary" role="button"	>Cite</a>
                            <!-- <a href="publication/fssgq-ghosh-slides.pdf" class="btn btn-primary" role="button"	>Slides</a> -->
                            <a href="https://github.com/meelgroup/justicia" class="btn btn-primary" role="button"	>Code</a>
                            <!-- <a href="https://www.dropbox.com/s/7njeqwajgtb6696/lexr.mov?dl=0" class="btn btn-primary" role="button"	>Talk</a> -->
                            <!-- <a href="https://www.dropbox.com/s/01qg1x3xt7as7n0/lexr.pptx?dl=0" class="btn btn-primary" role="button"	>Slides</a> -->
                            <a href="https://drive.google.com/file/d/1B9vV9FmhH8FUuOzmU6wPgVPWq1JUB2Ki/view?usp=sharing" class="btn btn-primary" role="button"	><small>Podcast [Experimental]</small></a>
                                                            
        
                        <div id="fvgm" class="collapse">
                            <p align="justify">
                                In recent years, machine learning (ML) algorithms have been deployed in safety-critical and 
                                high-stake decision-making, where the fairness of algorithms is of paramount importance. 
                                Fairness in ML centers on detecting bias towards certain demographic populations induced 
                                by an ML classifier and proposes algorithmic solutions to mitigate the bias with respect 
                                to different fairness definitions. To this end, several fairness verifiers have been proposed 
                                that compute the bias in the prediction of an ML classifier -- essentially beyond a 
                                finite dataset -- given the probability distribution of input features. 
                                In the context of verifying linear classifiers, existing fairness verifiers are limited 
                                by accuracy due to imprecise modelling of correlations among features and scalability
                                due to restrictive formulations of the classifiers as SSAT or SMT formulas or by 
                                sampling. 
                            </p>

                            <p align="justify">
                                In this paper, we propose an efficient fairness verifier, called FVGM, 
                                 that encodes the correlations among features as a Bayesian network. In contrast to 
                                 existing verifiers, FVGM proposes a stochastic subset-sum based approach for verifying 
                                 linear classifiers. Experimentally, we show that FVGM leads to an accurate and 
                                 scalable assessment for more diverse families of fairness-enhancing algorithms, 
                                 fairness attacks, and group/causal fairness metrics than the state-of-the-art. 
                                 We also demonstrate that FVGM facilitates the computation of fairness influence functions 
                                 as a stepping stone to detect the source of bias induced by subsets of features.
                            </p>
                        </div>
                    </div>
                    
                </div>
            </div>
            

            <div class="container">
                <br>
                <div class="row">
                    <div class="col-md-1">
                            <span class="serial">
                            <strong> JAIR  </strong><br />
                        </span>

                    </div>
                    <div class="col-md-8">
                        <h3><a href="https://arxiv.org/pdf/2205.06936.pdf">Efficient Learning of Interpretable Classification Rules</a></h3>
                        <h4> <u>Bishwamittra Ghosh</u>, Dmitry Malioutov, Kuldeep S. Meel.</h4> 
                        <!-- <h4>Proceedings of JAIR, 2022.</h4>     -->
                        <button type="button" class="btn btn-primary collapsed" data-toggle="collapse" data-target="#jair_imli">Abstract</button>
                            <a href="https://arxiv.org/pdf/2205.06936.pdf" class="btn btn-primary" role="button">PDF</a>
                            <a href="publication/jair_2022/paper.bib" class="btn btn-primary" role="button"	>Cite</a>
                            <!-- <a href="publication/fssgq-ghosh-slides.pdf" class="btn btn-primary" role="button"	>Slides</a> -->
                            <a href="https://github.com/meelgroup/mlic" class="btn btn-primary" role="button"	>Code</a>
                            <!-- <a href="https://www.dropbox.com/s/7njeqwajgtb6696/lexr.mov?dl=0" class="btn btn-primary" role="button"	>Talk</a> -->
                            <!-- <a href="https://www.dropbox.com/s/01qg1x3xt7as7n0/lexr.pptx?dl=0" class="btn btn-primary" role="button"	>Slides</a> -->
                            <a href="https://drive.google.com/file/d/1TXZhGAbKfTC9Osw8SqONzCz5luoPuaF-/view?usp=sharing" class="btn btn-primary" role="button"	><small>Podcast [Experimental]</small></a>
                                                            
        
                        <div id="jair_imli" class="collapse">
                            <p align="justify">
                                Machine learning has become omnipresent with applications in various safety-critical
                                domains such as medical, law, and transportation. In these domains, high-stake decisions
                                provided by machine learning necessitate researchers to design interpretable models, where
                                the prediction is understandable to a human. In interpretable machine learning, rule-based
                                classifiers are particularly effective in representing the decision boundary through a set of
                                rules comprising input features. Examples of such classifiers include decision trees, decision
                                lists, and decision sets. The interpretability of rule-based classifiers is in general related to
                                the size of the rules, where smaller rules are considered more interpretable. To learn such
                                a classifier, the brute-force direct approach is to consider an optimization problem that
                                tries to learn the smallest classification rule that has close to maximum accuracy. This
                                optimization problem is computationally intractable due to its combinatorial nature and
                                thus, the problem is not scalable in large datasets. To this end, in this paper we study
                                the triangular relationship among the accuracy, interpretability, and scalability of learning
                                rule-based classifiers. 
                            </p>

                            <p align="justify">
                                The contribution of this paper is an interpretable learning framework IMLI, that is
                                based on maximum satisfiability (MaxSAT) for synthesizing classification rules expressible
                                in proposition logic. IMLI considers a joint objective function to optimize the accuracy
                                and the interpretability of classification rules and learns an optimal rule by solving an
                                appropriately designed MaxSAT query. Despite the progress of MaxSAT solving in the
                                last decade, the straightforward MaxSAT-based solution cannot scale to practical classification datasets containing thousands to millions of samples. Therefore, we incorporate
                                an efficient incremental learning technique inside the MaxSAT formulation by integrating
                                mini-batch learning and iterative rule-learning. The resulting framework learns a classifier
                                by iteratively covering the training data, wherein in each iteration, it solves a sequence
                                of smaller MaxSAT queries corresponding to each mini-batch. In our experiments, IMLI
                                achieves the best balance among prediction accuracy, interpretability, and scalability. For
                                instance, IMLI attains a competitive prediction accuracy and interpretability w.r.t. existing
                                interpretable classifiers and demonstrates impressive scalability on large datasets where
                                both interpretable and non-interpretable classifiers fail. As an application, we deploy IMLI
                                in learning popular interpretable classifiers such as decision lists and decision sets.
                            </p>
                        </div>
                    </div>
                    
                </div>
            </div>


            
        </div>
        

    <div class="publication-block">
        <h1 class="heading">2021</h1>

        
        <div class="container">
            <div class="row">
                <div class="col-md-1">
                        <span class="serial">
                        <strong> AAAI  </strong><br />
                    </span>

                </div>
                <div class="col-md-8">
                    <h3><a href="https://arxiv.org/pdf/2009.06516.pdf">Justicia: A Stochastic SAT Approach to Formally Verify Fairness</a></h3>
                    <h4> <u>Bishwamittra Ghosh</u>, Debabrota Basu, Kuldeep S. Meel</h4> 
                    <!-- <h4>Proceedings of AAAI, 2021.</h4> -->
                    <button type="button" class="btn btn-primary collapsed" data-toggle="collapse" data-target="#justicia">Abstract</button>
                        <a href="https://arxiv.org/pdf/2009.06516.pdf" class="btn btn-primary" role="button">PDF</a>
                        <a href="publication/justicia/paper.bib" class="btn btn-primary" role="button"	>Cite</a>
                        <a href="publication/justicia/presentation.pdf" class="btn btn-primary" role="button"	>Slides</a>
                        <a href="publication/justicia/poster.pdf" class="btn btn-primary" role="button"	>Poster</a>
                        <a href="https://github.com/meelgroup/justicia" class="btn btn-primary" role="button"	>Code</a>
                        <!-- <a href="https://studio.slideslive.com/web_recorder/share/20210108T082957Z__AAAI__0678__justicia-a-stochastic-sat-app?s=b9277b7b-366b-4627-9380-66973c315fee" class="btn btn-primary" role="button"	>Talk</a> -->
                        <a href="https://drive.google.com/file/d/1_h5WEmALIkqytLbRb3pKJ9rHO9TfDn_X/view?usp=sharing" class="btn btn-primary" role="button"	><small>Podcast [Experimental]</small></a>
                                                        
    
                    <div id="justicia" class="collapse">
                        <p align="justify">
                            As a technology ML is oblivious to societal good or bad, and thus, the field of fair machine
                            learning has stepped up to propose multiple mathematical definitions, algorithms, and
                            systems to ensure different notions of fairness in ML applications. Given the multitude of
                            propositions, it has become imperative to formally verify the fairness metrics satisfied by
                            different algorithms on different datasets. In this paper, we propose a stochastic satisfiability
                            (SSAT) framework, Justicia, that formally verifies different fairness measures of supervised
                            learning algorithms with respect to the underlying data distribution. We instantiate Justicia
                            on multiple classification and bias mitigation algorithms, and datasets to verify different
                            fairness metrics, such as disparate impact, statistical parity, and equalized odds. Justicia is
                            scalable, accurate, and operates on non-Boolean and compound sensitive attributes unlike
                            existing distribution-based verifiers, such as FairSquare and VeriFair. Being distribution-based
                            by design, Justicia is more robust than the verifiers, such as AIF360, that operate
                            on specific test samples. We also theoretically bound the finite-sample error of the verified
                            fairness measure.
                        </p>
                    </div>
                </div>
                
            </div>
        </div>

        <div class="container">
            <br>
            <div class="row">
                <div class="col-md-1">
                        <span class="serial">
                        <strong> TSAS  </strong><br />
                    </span>

                </div>
                <div class="col-md-8">
                    <h3><a href="https://dl.acm.org/doi/full/10.1145/3475962?accessTab=true">Social-Spatial Group Queries with Keywords</a></h3>
                    <h4> Sajid Hasan Apon, Mohammed Eunus Ali, <u>Bishwamittra Ghosh</u>, Timos Sellis</h4> 
                    <!-- <h4>ACM Transactions on Spatial Algorithms and Systems (TSAS), 2021.</h4> -->
                    <button type="button" class="btn btn-primary collapsed" data-toggle="collapse" data-target="#sskgq">Abstract</button>
                        <a href="https://dl.acm.org/doi/full/10.1145/3475962?accessTab=true" class="btn btn-primary" role="button">PDF</a>
                        <a href="publication/sskgq/paper.bib" class="btn btn-primary" role="button"	>Cite</a>
                        <!-- <a href="publication/justicia/presentation.pdf" class="btn btn-primary" role="button"	>Slides</a> -->
                        <!-- <a href="publication/justicia/poster.pdf" class="btn btn-primary" role="button"	>Poster</a> -->
                        <!-- <a href="https://github.com/meelgroup/justicia" class="btn btn-primary" role="button"	>Code</a> -->
                        <!-- <a href="https://studio.slideslive.com/web_recorder/share/20210108T082957Z__AAAI__0678__justicia-a-stochastic-sat-app?s=b9277b7b-366b-4627-9380-66973c315fee" class="btn btn-primary" role="button"	>Talk</a> -->
                                                        
    
                    <div id="sskgq" class="collapse">
                        <p align="justify">
                            Social networks with location enabling technologies, also known as geo-social networks, allow users to share their location-specific activities and preferences through check-ins. A user in such a geo-social network can be attributed to an associated location (spatial), her preferences as keywords (textual), and the connectivity (social) with her friends. The fusion of social, spatial, and textual data of a large number of users in these networks provide an interesting insight for finding meaningful geo-social groups of users supporting many real-life applications, including activity planning and recommendation systems. In this article, we introduce a novel query, namely, Top-k Flexible Socio-Spatial Keyword-aware Group Query (SSKGQ), which finds the best k groups of varying sizes around different points of interest (POIs), where the groups are ranked based on the social and textual cohesiveness among members and spatial closeness with the corresponding POI and the number of members in the group. We develop an efficient approach to solve the SSKGQ problem based on our theoretical upper bounds on distance, social connectivity, and textual similarity. We prove that the SSKGQ problem is NP-Hard and provide an approximate solution based on our derived relaxed bounds, which run much faster than the exact approach by sacrificing the group quality slightly. Our extensive experiments on real data sets show the effectiveness of our approaches in different real-life settings.
                        </p>
                    </div>
                </div>
                
            </div>
        </div>


    </div>

    <div class="publication-block">

        <h1 class="heading">2020</h1>


        <div class="container">
            <div class="row">
                <div class="col-md-1">
                     <span class="serial">
                        <strong> AAAI  </strong><br />
                    </span>

                </div>
                <div class="col-md-8">
                    <h3><a href="publication/aaai_2020/AAAI-CiampiconiL.690.pdf">A MaxSAT-based Framework for Group Testing</a></h3>
                    <h4> Lorenzo Ciampiconi, <u>Bishwamittra Ghosh</u>, Jonathan Scarlett, Kuldeep S. Meel.</h4> 

                    <!-- <h4>Proceedings of AAAI, 2020.</h4> -->
                    <button type="button" class="btn btn-primary collapsed" data-toggle="collapse" data-target="#mgt">Abstract</button>
                      <a href="publication/aaai_2020/AAAI-CiampiconiL.690.pdf" class="btn btn-primary" role="button">PDF</a>
                      <a href="https://github.com/meelgroup/mgt
                    " class="btn btn-primary" role="button">Code</a>
                    <a href="publication/aaai_2020/AAAI-CiampiconiL.690.bib" class="btn btn-primary" role="button">Cite</a>
                    <div id="mgt" class="collapse">
                        <p align="justify">
                            The success of MaxSAT (maximum satisfiability) solving in recent years has motivated researchers
                                to apply MaxSAT solvers in diverse discrete combinatorial optimization problems. 
                                Group testing has been studied as a combinatorial optimization problem, 
                                where the goal is to find defective items among a set of items by performing sets 
                                of tests on items. In this paper, we propose a MaxSAT-based framework, called MGT, 
                                that solves group testing, in particular, the decoding phase of non-adaptive group 
                                testing. We extend this approach to the noisy variant of group testing, and propose 
                                a compact MaxSAT-based encoding that guarantees an optimal solution. Our extensive 
                                experimental results show that MGT can solve group testing instances of 10000 
                                items with 3% defectivity, which no prior work can handle to the best of our knowledge. 
                                Furthermore, MGT has better accuracy than the LP-based approach. We also discover an 
                                interesting phase transition behavior in the runtime, which reveals the easy-hard-easy 
                                nature of group testing.
                        </p>
                    </div>
                </div>

            </div>
        </div>
        

        <div class="container">
            <br>
            <div class="row">
                <div class="col-md-1">
                     <span class="serial">
                        <strong> ECAI  </strong><br />
                    </span>

                </div>
                <div class="col-md-8">
                    <h3><a href="publication/ecai_2020/paper.pdf">Classification Rules in Relaxed Logical Form</a></h3>
                        <h4> <u>Bishwamittra Ghosh</u>, Dmitry Malioutov, Kuldeep S. Meel.</h4> 
    
                        <h4>Proceedings of ECAI, 2020.</h4>
                        <button type="button" class="btn btn-primary collapsed" data-toggle="collapse" data-target="#crr">Abstract</button>
                        <a href="publication/ecai_2020/paper.pdf" class="btn btn-primary" role="button">PDF</a>
                        <a href="https://github.com/meelgroup/mlic
                        " class="btn btn-primary" role="button">Code</a>
                        <a href="publication/ecai_2020/paper.bib" class="btn btn-primary" role="button">Cite</a>
                    <div id="crr" class="collapse">
                        <p align="justify">
                            Machine learning algorithms that produce rule-based predictions
                                in Conjunctive Normal form (CNF) or in Disjunctive Normal form (DNF)
                                are arguably some of the most interpretable ones. For example,
                                decision set is an interpretable model in practice, that
                                represents the decision function in the form of DNF. 
                                In this paper, we consider relaxed definitions of standard 
                                OR/AND operators which allow exceptions in the construction of 
                                a clause and also in the selection of clauses in a rule. 
                                Building on these relaxed definition, we introduce relaxed-CNF rules, 
                                which are motivated by the popular usage of checklists in 
                                the medical domain and generalizes the widely employed rule 
                                representations including CNF, DNF, and decision sets. While 
                                the combinatorial structure of relaxed-CNF rules offers exponential 
                                succinctness, the naive learning techniques are computationally 
                                expensive. To this end, we propose a novel incremental mini-batch 
                                learning procedure, called CRR, that employs advances in the 
                                Mixed-Integer Linear Programming (MILP) solvers to efficiently 
                                learn relaxed-CNF rules. Our experimental analysis demonstrates 
                                that CRR can generate relaxed-CNF rules, which are more accurate 
                                and sparser compared to the alternative rule-based models.
                        </p>
                    </div>
                </div>

            </div>
        </div>


    
        
    </div>

    <div class="publication-block">
        <h1 class="heading">2019</h1>
    
        <div class="container">
            <div class="row">
                <div class="col-md-1">
                     <span class="serial">
                        <strong> AIES  </strong><br />
                    </span>

                </div>
                <div class="col-md-8">
                    <h3><a href="publication/imli-ghosh.pdf">IMLI: An Incremental Framework for MaxSAT-Based Learning of Interpretable Classification Rules</a></h3>
                    <h4> <u>Bishwamittra Ghosh</u>, Kuldeep S. Meel.</h4> 

                    <!-- <h4>Proceedings of AAAI/ACM Conference on AI, Ethics, and Society (AIES), 2019.</h4> -->
                    <button type="button" class="btn btn-primary collapsed" data-toggle="collapse" data-target="#imli">Abstract</button>
                      <a href="publication/imli-ghosh.pdf" class="btn btn-primary" role="button">PDF</a>
                      <a href="publication/imli-ghosh-poster.pdf" class="btn btn-primary" role="button">Poster</a>
                      <a href="publication/imli-ghosh.bib" class="btn btn-primary" role="button">Cite</a>
                      <a href="https://github.com/meelgroup/MLIC
                    " class="btn btn-primary" role="button">Code</a>
                    <a href="publication/imli-ghosh-slides.pdf" class="btn btn-primary" role="button">Slides</a>
                    <a href="imli.html" class="btn btn-primary" role="button">Blog</a>

<!-- 	  					<a href="publication/fssgq-ghosh.bib" class="btn btn-primary" role="button"	>Cite</a>
-->
  
                    <div id="imli" class="collapse">
                        <p align="justify">
                            The wide adoption of machine learning in the critical domains such as medical diagnosis, law, education had propelled the need for interpretable techniques due to the need for end user to understand the reasoning behind decisions due to learning systems. The computational intractability of interpretable learning led practitioners to design heuristic techniques, which fail to provide sound handles to tradeoff accuracy and interpretability.
                        </p>
                        <p align="justify">
                            Motivated by the success of MaxSAT solvers over the past decade, recently MaxSAT-based approach, called MLIC, was proposed that seeks to reduce the problem of learning interpretable rules expressed in Conjunctive Normal Form (CNF) to a MaxSAT query. While MLIC was shown to achieve accuracy similar to that of other state oft he art black-box classifiers while generating small interpretable CNF formulas, the runtime performance of MLIC is significantly lagging and renders approach unusable in practice. In this context, authors raised the question: <i>	Is it possible to achieve the best of both worlds, i.e., a sound framework for interpretable learning that can take advantage of MaxSAT solvers while scaling to real-world instances?					
                            </i></p>

                        <p align="justify">
                            In this paper, we take a step towards answering the above question in affirmation. We propose an incremental approach to MaxSAT based framework that achieves scalable runtime performance via partition-based training methodology. Extensive experiments on benchmarks arising from UCI repository demonstrate that IMLI achieves up to three orders of magnitude runtime improvement without loss of accuracy and interpretability.
                        </p>
                    </div>
                </div>

            </div>
        </div>

    </div>

        <div class="publication-block">
            <h1 class="heading">2018</h1>
        
            <div class="container">
                <div class="row">
                    <div class="col-md-1">
                         <span class="serial">
                            <strong> VLDB  </strong><br />
                        </span>

                    </div>
                    <div class="col-md-8">
                        <h3><a href="publication/fssgq-ghosh.pdf">The Flexible Socio Spatial Group Queries</a></h3>
                        <h4> <u>Bishwamittra Ghosh</u>, Mohammed Eunus Ali, Farhana M. Choudhury,</h4> 

                        <h4>Sajid Hasan Apon, Timos Sellis, Jianxin Li.</h4>
                        <!-- <h4>Proceedings of the VLDB Endowment (PVLDB), 2018.</h4> -->
                        <button type="button" class="btn btn-primary collapsed" data-toggle="collapse" data-target="#fssgq">Abstract</button>
                          <a href="publication/fssgq-ghosh.pdf" class="btn btn-primary" role="button">PDF</a>
                          <a href="publication/fssgq-ghosh.bib" class="btn btn-primary" role="button"	>Cite</a>
                          <a href="publication/fssgq-ghosh-slides.pdf" class="btn btn-primary" role="button"	>Slides</a>

      
                        <div id="fssgq" class="collapse">
                            <p align="justify">
                                A socio spatial group query finds a group of users who possess strong social connections with each other and have the minimum aggregate spatial distance to a meeting point. Existing studies limit the socio spatial group search to either finding best group of a fixed size for a single meeting location, or a single group of a fixed size w.r.t. multiple meeting locations. However, it is highly desirable to consider multiple meeting locations/POIs in a real-life scenario in order to organize impromptu activities of user groups of various sizes. In this paper, we propose Top k Flexible Socio Spatial Group Query (Top k-FSSGQ) to find and rank the top k groups w.r.t. multiple POIs where each group follows the minimum social connectivity constraints. We devise a ranking function to measure the group score by combining social closeness, spatial distance, and group size, which provides the flexibility of choosing groups of different sizes under different constraints. To effectively process the Top k-FSSGQ, we first develop an Exact approach that ensures early termination of the search based on the derived upper bounds. We prove that the problem is NP-hard, hence we first present a heuristic based approximation algorithm to effectively select members in intermediate solution groups based on the social connectivity of the users. Later we design a Fast Approximate approach based on the relaxed social and spatial bounds, and connectivity constraint heuristic. Experimental studies have verified the effectiveness and efficiency of our proposed approaches on real datasets.
                            </p>
                        </div>
                    </div>
                    
                </div>
            </div>

        


        
    </div>
    

        
        
        
            
            
        
        <!-- <p align="middle"><a href="publications.html">All publications...</a>.</p> -->
    
    </div>

    
    
	<div id="experience" class="background-alt">
        <h2 class="heading"><a href="news.html">News</a></h2>
        <div id="experience-timeline">
            
            <div data-date="12 July 2025">
                <p>
                    
                    Our <a href="https://arxiv.org/pdf/2403.07151">paper</a> has been accepted at ECAI 2025. Federated learning relies on collaboration among distributed clients with local data. In this work, we propose a game-theoretic framework to quantify client contributions as they dynamically participate in the learning process.

               	</p>
            </div>


            <div data-date="11 June 2025">
                <p>
                    Awarded <span style="color: #e74c3c">Outstanding Reviewer</span> at KDD 2025 (February cycle). 
                    
               	</p>
            </div>



            <div data-date="23 January 2025">
                <p>
                    How logically consistent large language models (LLMs) are? In our <a href="https://arxiv.org/pdf/2412.16100">ICLR paper</a>, we propose a framework for assessing and improving logical consistency of LLMs in fact-checking.
                    This is a joint work with Sarah Hasan, Naheed Anjum Arafat, and Arijit Khan.
               	</p>
            </div>


            <div data-date="10 December 2024">
                <p>
                    Our paper on <a href="https://arxiv.org/pdf/2410.08111">ML auditing via Fourier Analysis</a> is accepted in AAAI 2025. This is a collaboration with Ayoub and Deb from Inria, France.
               	</p>
            </div>

            <div data-date="24 October 2024">
                <p>
                    Our paper on reliable knowledge estimation in LLMs is accepted at <a href="https://www.wsdm-conference.org/2025/">WSDM, 2025</a>. We propose a simple method that can reliably estimate the latent knowledge across multiple LLMs and relation queries.
               	</p>
            </div>

            
                        
           
        </div>
        <p align="middle"><a href="news.html">All news...</a>.</p>
        
    </div>
    <!-- End #news -->


    <div id="projects" class="background-alt">
        <h2 class="heading"><a href="blog.html">Blog</a></h2>
        <div id="projects" class="background-alt">
            <div class="container">
                <div class="row">
                    <div class="no-image">
                          <div class="project-info">
                              [IJCAI-2023 tutorial] <a href="https://auditing-fairness-tutorial.github.io">Auditing Bias of Machine Learning Algorithms: Tools and Overview</a> 
                              <br>
                              <br>
                              <a href="justicia.html">Fairness Verification in Machine Learning: A Formal Methods Approach</a>
                              <br>
                              <br>
                              <a href="imli.html">IMLI: Incremental learning of interpretable classification rules</a>
                          </div>
                    </div>
                </div>
          </div>   
    </div>
    <!-- End #projects -->

    

    <footer>
        <div class="container">
            <div class="row">
                <div class="col-sm-5 copyright">
                </div>
                <div class="col-sm-2 top">
                    <span id="to-top">
                        <i class="fa fa-chevron-up" aria-hidden="true"></i>
                    </span>
                </div>
            </div>
        </div>
    </footer>
    <!-- End footer -->

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>
    <script src="js/scripts.min.js"></script>
</body>

</html>
