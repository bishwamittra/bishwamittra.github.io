<!DOCTYPE html>
<html class="no-js" lang="en">
 <!-- change made in online -->
<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Publications</title>
	<link rel="shortcut icon" href="images/pp.jpg" type="image/x-icon">
	<link rel="icon" href="images/pp.jpg" type="image/x-icon">
    <link href="https://fonts.googleapis.com/css?family=Lato:300,400,700,900" rel="stylesheet">
    
    <link href="css/bootstrap.min.css" rel="stylesheet">
    <link href="css/styles.css" rel="stylesheet">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css">
	<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  	<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"></script>
  	<link rel="stylesheet" href="libs/font-awesome/css/font-awesome.min.css">
  	<link href="css/styles.css" rel="stylesheet">
    
</head>

<body>
    

    <div id="mobile-menu-open" class="shadow-large">
        <i class="fa fa-bars" aria-hidden="true"></i>
    </div>
    <!-- End #mobile-menu-toggle -->
    <header>
        <div id="mobile-menu-close">
            <span>Close</span> <i class="fa fa-times" aria-hidden="true"></i>
        </div>
        <ul id="menu" class="shadow">
            
            <li>
                <a href="index.html" onClick="window.location='index.html'"">Home</a>
            </li>
            <li>
                    <a href="publications.html" onClick="window.location='publications.html'"">Publications</a>
            </li>
            <li>
                <a href="education.html" onClick="window.location='education.html'"">Education</a>
            </li>
            <li>
                <a href="blog.html" onClick="window.location='blog.html'"">Blog</a>
            </li>
            <li>
                <a href="activities.html" onClick="window.location='activities.html'"">Activities</a>
            </li>
            <li>
                    <a href="news.html" onClick="window.location='news.html'"">News</a>
            </li>
            
        </ul>
    </header>
    <br>
    <br>
    
    <div id="publication">
    
        
        

    <h2 class="heading">Conference Papers</h2>

    <div class="publication-block">
        <h1 class="heading">2022</h1>

        <div class="container">
            <div class="row">
                <div class="col-md-1">
                        <span class="serial">
                        <strong> [C6]  </strong><br />
                    </span>

                </div>
                <div class="col-md-8">
                    <h3>Algorithmic Fairness Verification with Graphical Models </h3>
                    <h4> <strong>Bishwamittra Ghosh</strong>, Debabrota Basu, Kuldeep S. Meel</h4> 
                    <h4>Proceedings of AAAI, 2022.</h4>    
                    <button type="button" class="btn btn-primary collapsed" data-toggle="collapse" data-target="#fvgm">Abstract</button>
                        <a href="https://arxiv.org/pdf/2109.09447.pdf" class="btn btn-primary" role="button">PDF</a>
                        <a href="publication/fvgm/paper.bib" class="btn btn-primary" role="button"	>Cite</a>
                        <!-- <a href="publication/fssgq-ghosh-slides.pdf" class="btn btn-primary" role="button"	>Slides</a> -->
                        <a href="https://github.com/meelgroup/justicia" class="btn btn-primary" role="button"	>Code</a>
                        <!-- <a href="https://www.dropbox.com/s/7njeqwajgtb6696/lexr.mov?dl=0" class="btn btn-primary" role="button"	>Video</a> -->
                        <!-- <a href="https://www.dropbox.com/s/01qg1x3xt7as7n0/lexr.pptx?dl=0" class="btn btn-primary" role="button"	>Slides</a> -->
                                                        
    
                    <div id="fvgm" class="collapse">
                        <p align="justify">
                            In recent years, machine learning (ML) algorithms have been deployed in safety-critical and 
                            high-stake decision-making, where the fairness of algorithms is of paramount importance. 
                            Fairness in ML centers on detecting bias towards certain demographic populations induced 
                            by an ML classifier and proposes algorithmic solutions to mitigate the bias with respect 
                            to different fairness definitions. To this end, several fairness verifiers have been proposed 
                            that compute the bias in the prediction of an ML classifier -- essentially beyond a 
                            finite dataset -- given the probability distribution of input features. 
                            In the context of verifying linear classifiers, existing fairness verifiers are limited 
                            by accuracy due to imprecise modelling of correlations among features and scalability
                             due to restrictive formulations of the classifiers as SSAT or SMT formulas or by 
                             sampling. 
                        </p>

                        <p align="justify">
                            In this paper, we propose an efficient fairness verifier, called FVGM, 
                             that encodes the correlations among features as a Bayesian network. In contrast to 
                             existing verifiers, FVGM proposes a stochastic subset-sum based approach for verifying 
                             linear classifiers. Experimentally, we show that FVGM leads to an accurate and 
                             scalable assessment for more diverse families of fairness-enhancing algorithms, 
                             fairness attacks, and group/causal fairness metrics than the state-of-the-art. 
                             We also demonstrate that FVGM facilitates the computation of fairness influence functions 
                             as a stepping stone to detect the source of bias induced by subsets of features.
                        </p>
                    </div>
                </div>
                
            </div>
        </div>
    </div>
    

    <div class="publication-block">
        <h1 class="heading">2021</h1>

        <div class="container">
            <div class="row">
                <div class="col-md-1">
                        <span class="serial">
                        <strong> [C5]  </strong><br />
                    </span>

                </div>
                <div class="col-md-8">
                    <h3>Justicia: A Stochastic SAT Approach to Formally
                        Verify Fairness</h3>
                    <h4> <strong>Bishwamittra Ghosh</strong>, Debabrota Basu, Kuldeep S. Meel</h4> 
                    <h4>Proceedings of AAAI, 2021.</h4>
                    <button type="button" class="btn btn-primary collapsed" data-toggle="collapse" data-target="#justicia">Abstract</button>
                        <a href="https://arxiv.org/pdf/2009.06516.pdf" class="btn btn-primary" role="button">PDF</a>
                        <a href="publication/justicia/paper.bib" class="btn btn-primary" role="button"	>Cite</a>
                        <a href="publication/justicia/presentation.pdf" class="btn btn-primary" role="button"	>Slides</a>
                        <a href="publication/justicia/poster.pdf" class="btn btn-primary" role="button"	>Poster</a>
                        <a href="https://github.com/meelgroup/justicia" class="btn btn-primary" role="button"	>Code</a>
                        <a href="https://studio.slideslive.com/web_recorder/share/20210108T082957Z__AAAI__0678__justicia-a-stochastic-sat-app?s=b9277b7b-366b-4627-9380-66973c315fee" class="btn btn-primary" role="button"	>Video</a>
                                                        
    
                    <div id="justicia" class="collapse">
                        <p align="justify">
                            As a technology ML is oblivious to societal good or bad, and thus, the field of fair machine
                            learning has stepped up to propose multiple mathematical definitions, algorithms, and
                            systems to ensure different notions of fairness in ML applications. Given the multitude of
                            propositions, it has become imperative to formally verify the fairness metrics satisfied by
                            different algorithms on different datasets. In this paper, we propose a stochastic satisfiability
                            (SSAT) framework, Justicia, that formally verifies different fairness measures of supervised
                            learning algorithms with respect to the underlying data distribution. We instantiate Justicia
                            on multiple classification and bias mitigation algorithms, and datasets to verify different
                            fairness metrics, such as disparate impact, statistical parity, and equalized odds. Justicia is
                            scalable, accurate, and operates on non-Boolean and compound sensitive attributes unlike
                            existing distribution-based verifiers, such as FairSquare and VeriFair. Being distribution-based
                            by design, Justicia is more robust than the verifiers, such as AIF360, that operate
                            on specific test samples. We also theoretically bound the finite-sample error of the verified
                            fairness measure.
                        </p>
                    </div>
                </div>
                
            </div>
        </div>

    </div>

    <div class="publication-block">

        <h1 class="heading">2020</h1>


        <div class="container">
            <div class="row">
                <div class="col-md-1">
                     <span class="serial">
                        <strong> [C4]  </strong><br />
                    </span>

                </div>
                <div class="col-md-8">
                    <h3>A MaxSAT-based Framework for Group Testing</h3>
                    <h4> Lorenzo Ciampiconi, <strong>Bishwamittra Ghosh</strong>, Jonathan Scarlett, Kuldeep S. Meel.</h4> 

                    <h4>Proceedings of AAAI, 2020.</h4>
                    <button type="button" class="btn btn-primary collapsed" data-toggle="collapse" data-target="#mgt">Abstract</button>
                      <a href="publication/aaai_2020/AAAI-CiampiconiL.690.pdf" class="btn btn-primary" role="button">PDF</a>
                      <a href="https://github.com/meelgroup/mgt
                    " class="btn btn-primary" role="button">Code</a>
                    <a href="publication/aaai_2020/AAAI-CiampiconiL.690.bib" class="btn btn-primary" role="button">Cite</a>
                    <div id="mgt" class="collapse">
                        <p align="justify">
                            The success of MaxSAT (maximum satisfiability) solving in recent years has motivated researchers
                                to apply MaxSAT solvers in diverse discrete combinatorial optimization problems. 
                                Group testing has been studied as a combinatorial optimization problem, 
                                where the goal is to find defective items among a set of items by performing sets 
                                of tests on items. In this paper, we propose a MaxSAT-based framework, called MGT, 
                                that solves group testing, in particular, the decoding phase of non-adaptive group 
                                testing. We extend this approach to the noisy variant of group testing, and propose 
                                a compact MaxSAT-based encoding that guarantees an optimal solution. Our extensive 
                                experimental results show that MGT can solve group testing instances of 10000 
                                items with 3% defectivity, which no prior work can handle to the best of our knowledge. 
                                Furthermore, MGT has better accuracy than the LP-based approach. We also discover an 
                                interesting phase transition behavior in the runtime, which reveals the easy-hard-easy 
                                nature of group testing.
                        </p>
                    </div>
                </div>

            </div>
        </div>
        

        <div class="container">
            <div class="row">
                <div class="col-md-1">
                     <span class="serial">
                        <strong> [C3]  </strong><br />
                    </span>

                </div>
                <div class="col-md-8">
                    <h3>Classification Rules in Relaxed Logical Form</h3>
                        <h4> <strong>Bishwamittra Ghosh</strong>, Dmitry Malioutov, Kuldeep S. Meel.</h4> 
    
                        <h4>Proceedings of ECAI, 2020.</h4>
                        <button type="button" class="btn btn-primary collapsed" data-toggle="collapse" data-target="#crr">Abstract</button>
                        <a href="publication/ecai_2020/paper.pdf" class="btn btn-primary" role="button">PDF</a>
                        <a href="https://github.com/meelgroup/mlic
                        " class="btn btn-primary" role="button">Code</a>
                        <a href="publication/ecai_2020/paper.bib" class="btn btn-primary" role="button">Cite</a>
                    <div id="crr" class="collapse">
                        <p align="justify">
                            Machine learning algorithms that produce rule-based predictions
                                in Conjunctive Normal form (CNF) or in Disjunctive Normal form (DNF)
                                are arguably some of the most interpretable ones. For example,
                                decision set is an interpretable model in practice, that
                                represents the decision function in the form of DNF. 
                                In this paper, we consider relaxed definitions of standard 
                                OR/AND operators which allow exceptions in the construction of 
                                a clause and also in the selection of clauses in a rule. 
                                Building on these relaxed definition, we introduce relaxed-CNF rules, 
                                which are motivated by the popular usage of checklists in 
                                the medical domain and generalizes the widely employed rule 
                                representations including CNF, DNF, and decision sets. While 
                                the combinatorial structure of relaxed-CNF rules offers exponential 
                                succinctness, the naive learning techniques are computationally 
                                expensive. To this end, we propose a novel incremental mini-batch 
                                learning procedure, called CRR, that employs advances in the 
                                Mixed-Integer Linear Programming (MILP) solvers to efficiently 
                                learn relaxed-CNF rules. Our experimental analysis demonstrates 
                                that CRR can generate relaxed-CNF rules, which are more accurate 
                                and sparser compared to the alternative rule-based models.
                        </p>
                    </div>
                </div>

            </div>
        </div>


    
        
    </div>

    <div class="publication-block">
        <h1 class="heading">2019</h1>
    
        <div class="container">
            <div class="row">
                <div class="col-md-1">
                     <span class="serial">
                        <strong> [C2]  </strong><br />
                    </span>

                </div>
                <div class="col-md-8">
                    <h3>IMLI: An Incremental Framework for MaxSAT-Based Learning of Interpretable Classification Rules	</h3>
                    <h4> <strong>Bishwamittra Ghosh</strong>, Kuldeep S. Meel.</h4> 

                    <h4>Proceedings of AAAI/ACM Conference on AI, Ethics, and Society (AIES), 2019.</h4>
                    <button type="button" class="btn btn-primary collapsed" data-toggle="collapse" data-target="#imli">Abstract</button>
                      <a href="publication/imli-ghosh.pdf" class="btn btn-primary" role="button">PDF</a>
                      <a href="publication/imli-ghosh-poster.pdf" class="btn btn-primary" role="button">Poster</a>
                      <a href="publication/imli-ghosh.bib" class="btn btn-primary" role="button">Cite</a>
                      <a href="https://github.com/meelgroup/MLIC
                    " class="btn btn-primary" role="button">Code</a>
                    <a href="publication/imli-ghosh-slides.pdf" class="btn btn-primary" role="button">Slides</a>
                    <a href="imli.html" class="btn btn-primary" role="button">Blog</a>

<!-- 	  					<a href="publication/fssgq-ghosh.bib" class="btn btn-primary" role="button"	>Cite</a>
-->
  
                    <div id="imli" class="collapse">
                        <p align="justify">
                            The wide adoption of machine learning in the critical domains such as medical diagnosis, law, education had propelled the need for interpretable techniques due to the need for end user to understand the reasoning behind decisions due to learning systems. The computational intractability of interpretable learning led practitioners to design heuristic techniques, which fail to provide sound handles to tradeoff accuracy and interpretability.
                        </p>
                        <p align="justify">
                            Motivated by the success of MaxSAT solvers over the past decade, recently MaxSAT-based approach, called MLIC, was proposed that seeks to reduce the problem of learning interpretable rules expressed in Conjunctive Normal Form (CNF) to a MaxSAT query. While MLIC was shown to achieve accuracy similar to that of other state oft he art black-box classifiers while generating small interpretable CNF formulas, the runtime performance of MLIC is significantly lagging and renders approach unusable in practice. In this context, authors raised the question: <i>	Is it possible to achieve the best of both worlds, i.e., a sound framework for interpretable learning that can take advantage of MaxSAT solvers while scaling to real-world instances?					
                            </i></p>

                        <p align="justify">
                            In this paper, we take a step towards answering the above question in affirmation. We propose an incremental approach to MaxSAT based framework that achieves scalable runtime performance via partition-based training methodology. Extensive experiments on benchmarks arising from UCI repository demonstrate that IMLI achieves up to three orders of magnitude runtime improvement without loss of accuracy and interpretability.
                        </p>
                    </div>
                </div>

            </div>
        </div>

    </div>

        <div class="publication-block">
            <h1 class="heading">2018</h1>
        
            <div class="container">
                <div class="row">
                    <div class="col-md-1">
                         <span class="serial">
                            <strong> [C1]  </strong><br />
                        </span>

                    </div>
                    <div class="col-md-8">
                        <h3>The Flexible Socio Spatial Group Queries	</h3>
                        <h4> <strong>Bishwamittra Ghosh</strong>, Mohammed Eunus Ali, Farhana M. Choudhury,</h4> 

                        <h4>Sajid Hasan Apon, Timos Sellis, Jianxin Li.</h4>
                        <h4>Proceedings of the VLDB Endowment (PVLDB), 2019.</h4>
                        <button type="button" class="btn btn-primary collapsed" data-toggle="collapse" data-target="#fssgq">Abstract</button>
                          <a href="publication/fssgq-ghosh.pdf" class="btn btn-primary" role="button">PDF</a>
                          <a href="publication/fssgq-ghosh.bib" class="btn btn-primary" role="button"	>Cite</a>
                          <a href="publication/fssgq-ghosh-slides.pdf" class="btn btn-primary" role="button"	>Slides</a>

      
                        <div id="fssgq" class="collapse">
                            <p align="justify">
                                A socio spatial group query finds a group of users who possess strong social connections with each other and have the minimum aggregate spatial distance to a meeting point. Existing studies limit the socio spatial group search to either finding best group of a fixed size for a single meeting location, or a single group of a fixed size w.r.t. multiple meeting locations. However, it is highly desirable to consider multiple meeting locations/POIs in a real-life scenario in order to organize impromptu activities of user groups of various sizes. In this paper, we propose Top k Flexible Socio Spatial Group Query (Top k-FSSGQ) to find and rank the top k groups w.r.t. multiple POIs where each group follows the minimum social connectivity constraints. We devise a ranking function to measure the group score by combining social closeness, spatial distance, and group size, which provides the flexibility of choosing groups of different sizes under different constraints. To effectively process the Top k-FSSGQ, we first develop an Exact approach that ensures early termination of the search based on the derived upper bounds. We prove that the problem is NP-hard, hence we first present a heuristic based approximation algorithm to effectively select members in intermediate solution groups based on the social connectivity of the users. Later we design a Fast Approximate approach based on the relaxed social and spatial bounds, and connectivity constraint heuristic. Experimental studies have verified the effectiveness and efficiency of our proposed approaches on real datasets.
                            </p>
                        </div>
                    </div>
                    
                </div>
            </div>

        


        
    </div>


    <h2 class="heading">Journal Papers</h2>

    <div class="publication-block">
        <h1 class="heading">2021</h1>

        <div class="container">
            <div class="row">
                <div class="col-md-1">
                        <span class="serial">
                        <strong> [J1]  </strong><br />
                    </span>

                </div>
                <div class="col-md-8">
                    <h3>Social-Spatial Group Queries with Keywords</h3>
                    <h4> Sajid Hasan Apon, Mohammed Eunus Ali, <strong>Bishwamittra Ghosh</strong>, Timos Sellis</h4> 
                    <h4>ACM Transactions on Spatial Algorithms and Systems (TSAS), 2021.</h4>
                    <button type="button" class="btn btn-primary collapsed" data-toggle="collapse" data-target="#sskgq">Abstract</button>
                        <a href="https://dl.acm.org/doi/full/10.1145/3475962?accessTab=true" class="btn btn-primary" role="button">PDF</a>
                        <a href="publication/sskgq/paper.bib" class="btn btn-primary" role="button"	>Cite</a>
                        <!-- <a href="publication/justicia/presentation.pdf" class="btn btn-primary" role="button"	>Slides</a> -->
                        <!-- <a href="publication/justicia/poster.pdf" class="btn btn-primary" role="button"	>Poster</a> -->
                        <!-- <a href="https://github.com/meelgroup/justicia" class="btn btn-primary" role="button"	>Code</a> -->
                        <!-- <a href="https://studio.slideslive.com/web_recorder/share/20210108T082957Z__AAAI__0678__justicia-a-stochastic-sat-app?s=b9277b7b-366b-4627-9380-66973c315fee" class="btn btn-primary" role="button"	>Video</a> -->
                                                        
    
                    <div id="sskgq" class="collapse">
                        <p align="justify">
                            Social networks with location enabling technologies, also known as geo-social networks, allow users to share their location-specific activities and preferences through check-ins. A user in such a geo-social network can be attributed to an associated location (spatial), her preferences as keywords (textual), and the connectivity (social) with her friends. The fusion of social, spatial, and textual data of a large number of users in these networks provide an interesting insight for finding meaningful geo-social groups of users supporting many real-life applications, including activity planning and recommendation systems. In this article, we introduce a novel query, namely, Top-k Flexible Socio-Spatial Keyword-aware Group Query (SSKGQ), which finds the best k groups of varying sizes around different points of interest (POIs), where the groups are ranked based on the social and textual cohesiveness among members and spatial closeness with the corresponding POI and the number of members in the group. We develop an efficient approach to solve the SSKGQ problem based on our theoretical upper bounds on distance, social connectivity, and textual similarity. We prove that the SSKGQ problem is NP-Hard and provide an approximate solution based on our derived relaxed bounds, which run much faster than the exact approach by sacrificing the group quality slightly. Our extensive experiments on real data sets show the effectiveness of our approaches in different real-life settings.
                        </p>
                    </div>
                </div>
                
            </div>
        </div>

    </div>


    <h2 class="heading">Preprint</h2>

            
            

            <div class="publication-block">
                <h1 class="heading">2020</h1>

                <div class="container">
                    <div class="row">
                        <div class="col-md-1">
                                <span class="serial">
                                <strong> [P2]  </strong><br />
                            </span>
    
                        </div>
                        <div class="col-md-8">
                            <h3>Probably Approximately Correct Explanations of Machine
                                Learning Models via Syntax-Guided Synthesis</h3>
                                <h4> Daniel Neider, <strong>Bishwamittra Ghosh</strong></h4> 
                                <h4>arXiv preprint, 2020.</h4>
                            <button type="button" class="btn btn-primary collapsed" data-toggle="collapse" data-target="#pacXplainer">Abstract</button>
                                <a href="https://arxiv.org/pdf/2009.08770.pdf" class="btn btn-primary" role="button">PDF</a>
                                <a href="publication/pacX/paper.bib" class="btn btn-primary" role="button"	>Cite</a>
                                <!-- <a href="publication/fssgq-ghosh-slides.pdf" class="btn btn-primary" role="button"	>Slides</a> -->
                                <!-- <a href="https://github.com/bishwamittra/LEXR" class="btn btn-primary" role="button"	>Code</a> -->
                                <!-- <a href="https://www.dropbox.com/s/7njeqwajgtb6696/lexr.mov?dl=0" class="btn btn-primary" role="button"	>Video</a> -->
                                <!-- <a href="https://www.dropbox.com/s/01qg1x3xt7as7n0/lexr.pptx?dl=0" class="btn btn-primary" role="button"	>Slides</a> -->
                                                                
            
                            <div id="pacXplainer" class="collapse">
                                <p align="justify">
                                    We propose a novel approach to understanding the decision making of complex machine
                                    learning models (e.g., deep neural networks) using a combination of probably approximately correct
                                    learning (PAC) and a logic inference methodology called syntax-guided synthesis (SyGuS). We prove
                                    that our framework produces explanations that with a high probability make only few errors and show
                                    empirically that it is effective in generating small, human-interpretable explanations.
                                </p>
                            </div>
                        </div>
                        
                    </div>
                </div>
            
                

                <div class="container">
                    <div class="row">
                        <div class="col-md-1">
                                <span class="serial">
                                <strong> [P1]  </strong><br />
                            </span>
    
                        </div>
                        <div class="col-md-8">
                            <h3>A Formal Language Approach to Explaining RNNs</h3>
                            <h4> <strong>Bishwamittra Ghosh</strong>, Daniel Neider</h4> 
                            <h4>arXiv preprint, 2020.</h4>
                            <button type="button" class="btn btn-primary collapsed" data-toggle="collapse" data-target="#lexr">Abstract</button>
                                <a href="https://arxiv.org/pdf/2006.07292.pdf" class="btn btn-primary" role="button">PDF</a>
                                <a href="publication/lexr/paper.bib" class="btn btn-primary" role="button"	>Cite</a>
                                <!-- <a href="publication/fssgq-ghosh-slides.pdf" class="btn btn-primary" role="button"	>Slides</a> -->
                                <a href="https://github.com/bishwamittra/LEXR" class="btn btn-primary" role="button"	>Code</a>
                                <a href="https://www.dropbox.com/s/7njeqwajgtb6696/lexr.mov?dl=0" class="btn btn-primary" role="button"	>Video</a>
                                <a href="https://www.dropbox.com/s/01qg1x3xt7as7n0/lexr.pptx?dl=0" class="btn btn-primary" role="button"	>Slides</a>
                                                                
            
                            <div id="lexr" class="collapse">
                                <p align="justify">
                                    This paper presents LEXR, a framework for explaining the decision making of recurrent neural networks (RNNs) using a formal description language called Linear Temporal Logic (LTL). LTL is the de facto standard for the specification of temporal properties in the context of formal verification and features many desirable properties that make the generated explanations easy for humans to interpret: it is a descriptive language, it has a variable-free syntax, and it can easily be translated into plain English. To generate explanations, LEXR follows the principle of counterexample-guided inductive synthesis and combines Valiant's probably approximately correct learning (PAC) with constraint solving. We prove that LEXR's explanations satisfy the PAC guarantee (provided the RNN can be described by LTL) and show empirically that these explanations are more accurate and easier-to-understand than the ones generated by recent algorithms that extract deterministic finite automata from RNNs.
                                </p>
                            </div>
                        </div>
                        
                    </div>
                </div>
    
            </div>

    <!-- <h2 class="heading">Journal Papers</h2> -->

                



    <!-- <h2 class="heading">Workshop Papers</h2>

    <div class="publication-block">
        <h1 class="heading">2019</h1>
    
        <div class="container">
            <div class="row">
                <div class="col-md-1">
                     <span class="serial">
                        <strong> [W1]  </strong><br />
                    </span>

                </div>
                <div class="col-md-8">
                    <h3>Interpretable Classification Rules in Relaxed Logical Form	</h3>
                    <h4> <strong>Bishwamittra Ghosh</strong>, Dmitry Malioutov, Kuldeep S. Meel.</h4> 

                    <h4>IJCAI 2019 workshop on XAI (Explainable Artificial Intelligence) and DSO (Data Science meets Optimization).</h4>
                    <button type="button" class="btn btn-primary collapsed" data-toggle="collapse" data-target="#irr">Abstract</button>
                      <a href="publication/irr-ghosh.pdf" class="btn btn-primary" role="button">PDF</a>
                     
                    <a href="publication/irr-ghosh.bib" class="btn btn-primary" role="button">Cite (XAI)</a>
                    <a href="publication/irr-ghosh(DSO).bib" class="btn btn-primary" role="button">Cite (DSO)</a>
                      
                      <a href="https://github.com/meelgroup/IRR
                    " class="btn btn-primary" role="button">Code</a>

                    <a href="publication/irr-bishwa-slides.pdf" class="btn btn-primary" role="button">Slides</a>


                    <div id="irr" class="collapse">
                        <p align="justify">
                            Interpretability has become a central thread in ML research. As ML algorithms continue to permeate critical application domains such as medicine, legal, and transportation, it becomes increasingly important to allow human domain experts to understand and interact with ML solutions. ML algorithms that produce predictions in the form of rules are arguably some of the most interpretable ones, but their discrete combinatorial structure makes them computationally hard to learn. Here we generalize the widely popular CNF rules and introduce relaxed-CNF rules. These rules are much more flexible in terms of fitting data (have higher capacity) but about as interpretable to people as the traditional ones. We consider relaxed definitions of standard OR/AND operators which allow exceptions in the construction of a clause and also in the selection of clauses in a rule. We first describe an exact ILP solution, which is computationally expensive. We then propose an incremental solution, which allows us to generate accurate interpretable relaxed-CNF rules with significantly improved runtime performance.
                        </p>
                    </div>
                </div>

            </div>
        </div>
        
    </div> -->

    <!-- <h2 class="heading">Abstracts</h2>

    <div class="publication-block">
        <h1 class="heading">2019</h1>
    
        <div class="container">
            <div class="row">
                <div class="col-md-1">
                     <span class="serial">
                        <strong> [A1]  </strong><br />
                    </span>

                </div>
                <div class="col-md-8">
                    <h3>Incremental Approach to Interpretable Classification Rule Learning	</h3>
                    <h4> <strong>Bishwamittra Ghosh</strong>, Kuldeep S. Meel.</h4> 

                    <h4>CP 2019.</h4>
                    <a href="publication/cp_2019/imli.pdf" class="btn btn-primary" role="button">PDF</a>
                    <a href="publication/cp_2019/imli_poster.pdf" class="btn btn-primary" role="button">Poster</a>
                    

                    <a href="publication/cp_2019/presentation.pdf" class="btn btn-primary" role="button">Slides</a>


                    
                </div>

            </div>
        </div>
        
    </div> -->

<!-- </div> -->


    
    
    
    
    
   


    <footer>
        <div class="container">
            <div class="row">
                <div class="col-sm-5 copyright">
     <!--                <p>
                        Copyright &copy; 2018 Bishwamittra Ghosh
      -->               </p>
                </div>
                <div class="col-sm-2 top">
                    <span id="to-top">
                        <i class="fa fa-chevron-up" aria-hidden="true"></i>
                    </span>
                </div>
            </div>
        </div>
    </footer>
    <!-- End footer -->

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>
    <script src="js/scripts.min.js"></script>
</body>

</html>
