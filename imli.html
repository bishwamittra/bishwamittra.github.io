<!DOCTYPE html>
<html class="no-js" lang="en">
 <!-- change made in online -->
<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>IMLI: Incremental classification rule learning</title>
	<link rel="shortcut icon" href="images/pp.jpg" type="image/x-icon">
	<link rel="icon" href="images/pp.jpg" type="image/x-icon">
    <link href="https://fonts.googleapis.com/css?family=Lato:300,400,700,900" rel="stylesheet">
    
    <link href="css/bootstrap.min.css" rel="stylesheet">
    <link href="css/styles.css" rel="stylesheet">
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
          tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
        });
        </script>

    <script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
    </script>

    
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css">
	<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  	<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"></script>
  	<link rel="stylesheet" href="libs/font-awesome/css/font-awesome.min.css">
      <link href="css/styles.css" rel="stylesheet">
    
</head>


<body>
    

    <div id="mobile-menu-open" class="shadow-large">
        <i class="fa fa-bars" aria-hidden="true"></i>
    </div>
    <!-- End #mobile-menu-toggle -->
    <header>
        <div id="mobile-menu-close">
            <span>Close</span> <i class="fa fa-times" aria-hidden="true"></i>
        </div>
        <ul id="menu" class="shadow">
            
            <li>
                <a href="index.html" onClick="window.location='index.html'"">Home</a>
            </li>

            <li>
                    <a href="publications.html" onClick="window.location='publications.html'"">Publications</a>
            </li>
            <li>
                <a href="education.html" onClick="window.location='education.html'"">Education</a>
            </li>
            
            <li>
                    <a href="index.html#projects" onClick="window.location='index.html#projects'"">Blog</a>
            </li>

            <li>
                <a href="news.html" onClick="window.location='news.html'"">News</a>
            </li>

            
            
            
        </ul>
    </header>
    
    <br>
    
    <div id="projects" class="background-alt">
            <!-- <h2 class="heading">Blog</h2> -->
            <div class="container">
                <div class="row">
                    <div class="no-image">
                        <div class="project-info">
                            <h1>Incremental learning of interpretable classification rules</h1>
                            <h3><a href="index.html">Bishwamittra Ghosh</a></font></h3>

                            <h4 align="center"><a href="publication/imli-ghosh.pdf">Paper</a> <a href="https://github.com/meelgroup/MLIC">Code</a> <a href="publication/imli-ghosh.bib">Cite</a> <a href="publication/imli-ghosh-slides.pdf">Slides</a></h4>
                            <br>
                            <br>
                            <p align="justify" >

                                    Machine learning models are now being deployed in critical decision making, for example,
                                    hiring employees, giving a loan to a person, predicting recidivism, etc. 
                                    Therefore, end-users need to trust the model. Our primary motivation for
                                    this work is to design an interpretable rule-based classification model, 
                                    which generates highly interpretable smaller rules.
                            </p>
                            
                            <br>
                            <h2 align="left"> <font color="#148f77">Example of interpretable classification rules</font></h2>        
                            <p align="justify" >
                                    First, take a look at the Iris dataset, where each row represents a sample, and each column represents a feature/attribute of the Iris flower. An Iris flower has four features: sepal length, sepal width, petal length, and petal width. In supervised learning, each sample has a class label, i.e., there are three classes in the Iris dataset: Setosa, Versicolor, and Virginica. We can learn the following interpretable rule on the Iris dataset.
                            </p>
                            <img src="images/imli/iris_dataset.png" class="img-fluid" alt="Iris dataset" align="center" style="max-width:80%;
                            max-height:80%;">
                            <br>

                            
                            
                            <p align="justify"> 
                                    
                            
                                A sample is predicted <font color="blue">Iris Versicolor</font>  if <br>
                                    (sepal length $ > 6.3$   $\textbf{OR}$ sepal width $ > 3$   $\textbf{OR}$ petal width $\le 1.5 $ ) 
                                     $ \textbf{AND} $ <br>
                                    (sepal width $ \le 2.7$   $\textbf{OR}  $ petal length $ > 4$   $ \textbf{OR} $ petal width $ >1.2 $) 
                                     $ \textbf{AND} $ <br>
                                    (petal length $ \le 5 $)
                            </p>
                            <br>

                            
                            <p align="justify" >
                                    We can parse the above rule in the following way. An Iris flower is predicted as 
                                    Iris Versicolor if it satisfies the rule. The rule is a conjunction of three clauses, 
                                    where each clause is a disjunction of literals. A literal (i.e., sepal length $ > 6.3$)
                                    can take binary decisions (true or false). In the above rule, a clause is satisfied 
                                    when at least one literal is satisfied, and the rule is satisfied when all clauses 
                                    are satisfied. In this work, we are interested in learning classification rules 
                                    in the form of logical formulas.
                                
                            </p>
                            <br>

                            <h2 align="left"> <font color="#148f77">Revisiting logical formulas</font></h2>        
                            <p align="justify">
                                A logical formula in CNF (Conjunctive Normal Form) is a conjunction of clauses, where 
                                each clause is a disjunction of literals. Moreover, a formula in DNF (Disjunctive Normal
                                Form) is a disjunction of clauses, where each clause is a conjunction of literals. Given
                                Boolean propositional variables $ \{a,b,c,d,e\}$, an example of a CNF formula is 
                                $(a \vee \neg b  \vee c ) \wedge (d \vee e)$, and an example of a DNF formula is 
                                $(a \wedge b \wedge \neg  c ) \vee (d \wedge e)$. Here $\neg a$ denotes the complement of 
                                $a$. In several studies [Malioutov et al., 2018; Lakkaraju et al., 2019], it is found that classification rules 
                                in the form of CNF/DNF are highly interpretable. 
                            </p>
                            
                            <br>
                            <h2 align="left"> <font color="#148f77">Definition of Interpretibility</font></h2> 

                            <p align="justify">
                                    Defining the interpretability of a classifier is a challenging task. We have 
                                    narrowed down our look into rule-based classifiers and find that smaller 
                                    rules suffice in various practical domains, specifically in the medical domain.  
                                    The reason is that compared to larger rules, smaller rules are within reach of human 
                                    understandability. Therefore, we refer to the size of the rules as a proxy 
                                    in interpretability. 
                                    In CNF/DNF rules, rule size can be the total number of literals in the formula. 
                                
                            </p>

                            <br>
                            <h2 align="left"><font color="#148f77">Objective function and constraints</font></h2>

                            <p align="justify">
                                In the standard binary classification problem, we 
                                have designed an objective function to minimize both the prediction accuracy
                                and the size of the desired rule, so that the classifier can learn  accurate interpretable rules. 
                                In our model, features can take only binary values (0 or 1). For datasets with categorical and continuous features, 
                                we have applied 
                                standard discretization techniques to convert them into 
                                binary features. To learn a $k$-clause rule, we consider two types of Boolean propositional 
                                variables: 
                                <br>
                                <br>
                                (i) feature variable 
                                $ b_i^j = {1}\{j\text{-th feature} \text{ is selected in } i \text{-th clause} \}$, 
                                <br>(ii) 
                                noise variable  (classification error) $ \eta_q = {1}\{\text{sample } q \text{ is misclassified}\} $. 
                                
                                <br>
                                <br>
                                We have consider feature variables for both positive (1) feature value  and negative (0) feature value in
                                the binary featured dataset. In the following, we define the objective function. $$\min \sum_{i,j} b_i^j + \lambda \sum_q \eta_q$$

                                $\lambda$ is the data fidelity parameter deciding the trade-off between 
                                interpretability and accuracy. In this work, we optimize the objective function
                                subject to the constraints that a positive labeled sample satisfies the learned rule, and 
                                a negative labeled sample does not satisfy the rule, otherwise the sample is considered as a
                                classification noise. 
                                <br>
                                <br>
                                We encode the discrete optimization problem as a MaxSAT query and use a MaxSAT solver
                                for the assignment of the decision variables $b_i^j$ and $\eta_q $. 

                                
                            </p>
                            <br>
                            <h2 align="left" font="red" > <font color="#148f77">Revisiting MaxSAT</font></h2>   
                            <p align="justify">
                                    The maximum satisfiability problem (MaxSAT) is an optimization analog to
                                     the propositional satisfiability problem (SAT). In SAT, the goal is to 
                                     find an assignment to the Boolean variables that satisfies all the clauses.
                                      In MaxSAT, the objective is to find an assignment that satisfies most
                                       of the clauses. We consider a weighted variant of the CNF formula,
                                        where each clause is associated with weight and solve the partial
                                         weighted MaxSAT formula. Based on the weight, there are two types of clauses. 
                                <br>
                                <br>
                                (i) Hard clause: the weight is $\infty $
                                <br>
                                (ii) Soft clause: each clause can take weight $\in \mathbb{R}^+ $ 
                                <br>
                                <br>
                                In partial weighted MaxSAT, the goal is to find an assignment to the variables that satisfies
                                all hard clauses and most of the soft clauses such that the weight of the satisfied soft 
                                clauses in maximized.
                            </p>     
                            

                            <br>
                            <h2 align="left"> <font color="#148f77">MaxSAT encoding</font></h2>  
                            <p align="justify">
                                We encode the above objective function as soft clauses and the constraints as hard clauses 
                                to construct the MaxSAT  query (please refer to the <a href="publication/imli-ghosh.pdf">paper</a>
                                for details). We can use any off-the-shelf MaxSAT solver 
                                to solve the query. We finally construct the rule based on the assignment to the feature variables $b_i^j$.
                                


                            </p>
                            
                            <p align="justify">
                                We have analyzed the complexity of the MaxSAT query in terms of the number of 
                                clauses in the MaxSAT formula. 
                                 To generate a $ k $-clause CNF rule for a dataset of $ n $ samples over
                                $ m $ boolean features, the number of clauses of the MaxSAT
                                instance is $ \mathcal{O}(n\cdot m \cdot k) $. Therefore, the formula becomes large when 
                                the dataset has many samples. In the following, we propose an incremental mini-batch 
                                approach for learning interpretable classification rules.  
                            </p>

                            <br>
                            <h2 align="left"> <font color="#148f77">An Incremental Rule-learning Approach</font></h2>        
                            <img src="images/imli/framework.png" class="img-fluid" alt="Iris dataset" align="center" style="max-width:80%;
                            max-height:80%;">
                            <br>
                            <br>
                            <p align="justify">
                                We now discuss an incremental mini-batch learning approach, which can scale to large datasets. 
                                In this approach, we first split the datasets into a fixed number $p$ of batches. We propose to 
                                update the rule $\mathcal{R}$ incrementally over batches. The rule $\mathcal{R}_t$
                                in batch $t$ depends on the samples in the current batch and also the rule $\mathcal{R}_{t-1}$
                                learned in the previous batch. Note that, only the feature variable $b_i^j$ is shared in all batches 
                                because the samples in all batches have similar features. Therefore, while learning $\mathcal{R}_t$
                                we know the assignment to $b_i^j$ in the previous ($t-1$) batch. We consider the following objective
                                function in batch $t$. 
                                $$
                                \min \sum_{i,j} b_i^j \cdot I(b_i^j)+ \lambda \sum_q \eta_q.
                                $$
                                where indicator function $ I(\cdot) $ is defined as follows.
                                $$
                                I(b_i^j)=
                                \begin{cases}
                                -1 \quad \text{if }  b_i^j =1 \text{ in the }  (t-1) \text{-th batch } (t \ne 1)
                                \\
                                1 \quad \text{otherwise}
                                \end{cases}
                                $$

                                Intuitively, the objective function tries to keep the previous assignment to the feature 
                                variable $b_i^j$ while learning $\mathcal{R}_t$ in the current batch.

                                


                            
                             </p>
                             <p align="justify">
                                 <font color="red">Improvement:</font> The incremental approach makes  $ p $ queries to the 
                                 MaxSAT solver with each query of the formula size $ \mathcal{O}(\frac{n}{p}\cdot m \cdot k) $. 
                                 
                             </p>

                             <br>
                             <h2 align="left"> <font color="#148f77">Key experimental results</font></h2>  
                             <p align="justify">
                                 (i) The incremental approach achieves up to three orders of magnitude improvement in
                                 training time by sacrificing a bit of accuracy.
                                 <br>
                                 (ii) This approach generates shorter rules compared to other rule-based models.
                                 <br>
                                 (iii) The number of batches  provides a smooth trade-off 
                                 between training time and prediction accuracy.
                             </p>
                            

                            <br>
                            <h2 align="left"> <font color="#148f77">Conclusion</font></h2>        
                            
                            <p align="justify">
                                    The interpretable machine learning model ensures the reliability of
                                     prediction models in practice. We propose an incremental rule learning
                                      framework, which makes a step towards making the prediction model
                                       more reliable and trustworthy. This approach not only achieves
                                        an improvement in scalability but also generates shorter interpretable rules. 
 
                            </p>

                            <br>
                            <h2 align="left"> <font color="#148f77">Reference</font></h2>        
                            
                            <p align="justify">
                                [Malioutov et al., 2018] Dmitry Maliotov and Kuldeep S Meel.  MLIC: A MaxSAT-Based Framework for Learning 
                                Interpretable Classification Rules. In Proc. of CP, 2018.
                                <br>
                                <br>
                                [Lakkaraju et al., 2019] Himabindu Lakkaraju, Ece Kamar, Rich Caruana, and Jure Leskovec. 
                                Faithful and customizable explanations of black box models. In Proc. of AIES, 2019.
                            </p>    


                            
                        </div>

                            
                        <!-- End .project-info -->
                    </div>
                </div>
            </div>
        </div>


    
        <footer>
                <div class="container">
                    <div class="row">
                        <div class="col-sm-5 copyright">
                        </div>
                        <div class="col-sm-2 top">
                            <span id="to-top">
                                <i class="fa fa-chevron-up" aria-hidden="true"></i>
                            </span>
                        </div>
                    </div>
                </div>
            </footer>
            <!-- End footer -->
        
            <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>
            <script src="js/scripts.min.js"></script>

    
    
    
    
    
    
   


    

</body>

</html>
